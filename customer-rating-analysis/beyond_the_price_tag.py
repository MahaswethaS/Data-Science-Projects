# -*- coding: utf-8 -*-
"""Beyond the price tag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rYWhwLqkl872GglAvNUh56zNl27ChEb9

# Dataset
"""

!pip install opendatasets

import opendatasets as od

# URL of the Flipkart dataset on Kaggle
od.download("https://www.kaggle.com/datasets/niraliivaghani/flipkart-dataset")

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/flipkart-dataset/Dataset.csv',encoding='ISO-8859-1')

df.head()

# Check for any non-numeric values in the Price column
df['Price'].unique()  # This will help identify strange values like empty strings

# Remove any unwanted characters from the Price column and convert to numeric, forcing errors to NaN
df['Price'] = pd.to_numeric(df['Price'].replace({'[^0-9.]': ''}, regex=True), errors='coerce')

# Check if there are any NaN values after the conversion
df['Price'].isna().sum()

# Optionally, remove rows with NaN prices
df = df.dropna(subset=['Price'])

# Display the cleaned dataframe
df.head()

# Descriptive statistics for numerical columns
df.describe()

"""# Cleaning data"""

import pandas as pd
import re

# Define the category keywords
categories_keywords = {
    'Electronics': list(set([
        'dslr camera', 'remote', 'tata sky', 'airtel', 'google nest', 'bulb', 'lamp', 'lantern',
        'tv', 'charger', 'adapter', 'mobile phone', 'power bank', 'car amplifier',
        'wireless router', 'wifi', 'ink catridge', 'ipad', 'tablet', 'bluetooth home theatre',
        'bluetooth', 'jbl', 'boat', 'cable', 'hdmi', 'dish set', 'streaming device', 'asus',
        'keyboard', 'mouse', 'hp', 'i3', 'i5', 'i7', 'i9', 'spinbot', 'cd/dvd', 'wi-fi',
        'router', 'speaker', 'usb-c', 'inverter', 'ups', 'mobile', 'audio', 'lenovo', 'poco',
        'tds meter', 'android','printers'
    ])),
    'Appliances': [
        'dish washing gloves', 'kitchen platform', 'shower laser light', 'heater rod',
        'water purifier', 'garment steamer', 'refrigerator', 'washing machine', 'wet grinder',
        'air cooler', 'water geyser', 'vacuum cleaner', 'auto clean chimney', 'chimney', 'fan',
        'sewing machine', 'iron', 'water','dishwasher','washing machine','top load'
    ],
    'Sports and Apparel': [
        'sports cap', 'regular cap', 'plastic bat', 'abdomen support', 'cricket bat',
        'cricket stumps', 'stumps', 'tennis ball', 'football', 'wrist support',
        'wrist band', 'knee support', 'palm support', 'elbow support', 'ankle support',
        'cycling', 'cycle', 'safety shoes', 'skating shoe', 'skateboard', 'roller skates',
        'swimming kits', 'ear plugs', 'swimming', 'solid beanie', 'beanie', 'willow cricket bat',
        'mrf', 'cricket', 'exercise', 'thumb & finger sleeve', 'finger sleeves', 'leather','tummy trimmer'
        ,'silicone gel'
    ],
    'Beauty and Skin Care': [
        'face care kit', 'hair and care', 'skincare', 'moisturizer', 'serum', 'cream',
        'shampoo', 'beauty soap', 'face scrub', 'body scrub', 'hair & care', 'perfumes',
        'perfume', 'mask', 'parfum', 'envy', 'denver','kajal'
    ],
    'Cleaning Supplies': [
        'scotch-brite', 'hand gloves', 'dry glove set', 'spotzero', 'wash scrubber',
        'shower cleaner', 'dry broom', 'detergent', 'fabric conditioner', 'spin mop', 'broom',
        'mop', 'wet glove', 'dry glove', 'wet and dry glove', 'brush feather', 'cleaning cloth',
        'floor wiper', 'dustbin', 'home pest control', 'cleaning duster', 'duster', 'tuffy brush'
        ,'brush scrubber','bosch','kadai cleaning'
    ],
    'Furniture and Home': [
        'comforter', 'cushion pack', 'cotton runner', 'polyester runner', 'carpet', 'wallpaper',
        'chair', 'table', 'rack', 'shelf', 'stand', 'bookcase', 'computer desk', 'almirah',
        'cupboard', 'bedsheet', 'blanket', 'door mat', 'floor mat', 'mat', 'wardrobe',
        'pocket key holder', 'rosewood', 'rug', 'paint', 'emulsion', 'led', 'lights', 'wall',
        'furniture', 'milton', 'anti cut','key holder','sofa','wishpool','nimwash'
    ],
    'Party Supplies': [
        'happy birthday combo', 'balloon', 'decorations', 'smart kits'
    ],
    'Pooja Items': [
        'sambrani', 'incense holder', 'mix cones'
    ],
    'Stationery and Crafts': [
        'pencil', 'art', 'doms', 'colourup', 'ball pen', 'craft items', 'clock', 'crafts',
        'stationery', 'tape', 'adhesive', 'book', 'notes','writing pad','penstand','organizer box'
    ],
    'Toys': [
        'truck cars', 'helicopter', 'radio control race car', 'robot', 'remote control car',
        'modern car', 'flute', 'teddy', 'car'
    ],
    'Baking and Cooking': [
        'dinner set', 'cocoa powder', 'dry yeast', 'liquid food color', 'juicer',
        'grinder', 'juicer grinder', 'food processor', 'electric rice cooker', 'cooker',
        'kettle', 'single pot', 'oven', 'mixer grinder', 'silverware', 'stainless'
    ],
    'Baby Care': [
        'diaper', 'dancing cactus', 'temperado talking','mamypoko'
    ],
    'Health and Wellness': [
        'zandu balm', 'balm', 'multivitamin', 'nutrition', 'dettol'
    ]
}

# Categorization function using regex word boundaries
def categorize_product(name):
    if pd.isna(name):
        return 'Miscellaneous'
    name = name.lower()
    for category, keywords in categories_keywords.items():
        for kw in keywords:
            # Escape keyword for regex and use word boundaries
            pattern = r'\b' + re.escape(kw.lower()) + r'\b'
            if re.search(pattern, name):
                return category
    return 'Miscellaneous'

# Load dataset
df = pd.read_csv('/content/flipkart-dataset/Dataset.csv', encoding='latin1')

# Apply categorization
df['category'] = df['Product_name'].apply(categorize_product)

# Save updated dataset
df.to_csv('/content/flipkart_with_categories.csv', index=False)

print("Product categorization completed and saved.")

# Print first 10 rows with product name and new category
print(df[['Product_name', 'category']].head(10))

# Or print unique categories assigned
print(df['category'].unique())

print(df['category'].value_counts())

miscellaneous_items = df[df['category'] == 'Miscellaneous']
print(miscellaneous_items[['Product_name', 'category']])
miscellaneous_items.to_csv('miscellaneous_items.csv', index=False)

"""# Welch's Annova"""

pip install pandas numpy matplotlib seaborn pingouin scikit-posthocs

import pandas as pd
import numpy as np
import pingouin as pg
import scikit_posthocs as sp
import matplotlib.pyplot as plt
import seaborn as sns

# Load your dataset
df = pd.read_csv("/content/flipkart_with_categories.csv")

# Ensure 'Rate' is numeric and drop missing values
df['Rate'] = pd.to_numeric(df['Rate'], errors='coerce')
df = df.dropna(subset=['Rate', 'category'])

!pip install --upgrade scikit-posthocs

!pip install --upgrade scikit-posthocs

# Welch's ANOVA

welch_result = pg.welch_anova(dv='Rate', between='category', data=df)
print("Welchâ€™s ANOVA Result:\n", welch_result)

# Games-Howell Post Hoc Test
import pandas as pd
import numpy as np
from itertools import combinations
from scipy import stats

# Load your dataset
df = pd.read_csv('/content/flipkart_with_categories.csv')

# Ensure 'Rate' is numeric and drop nulls
df['Rate'] = pd.to_numeric(df['Rate'], errors='coerce')
df = df.dropna(subset=['Rate'])

# Group by category
groups = df.groupby('category')['Rate'].apply(list)

# Get unique pairs of categories
category_pairs = list(combinations(groups.index, 2))

# Games-Howell function
def games_howell(group1, group2):
    n1, n2 = len(group1), len(group2)
    mean1, mean2 = np.mean(group1), np.mean(group2)
    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)

    mean_diff = mean1 - mean2
    se = np.sqrt((var1 / n1) + (var2 / n2))

    df_denom = ((var1 / n1)**2 / (n1 - 1)) + ((var2 / n2)**2 / (n2 - 1))
    t_stat = np.abs(mean_diff) / se
    df = (var1 / n1 + var2 / n2)**2 / df_denom

    p_val = 2 * stats.t.sf(t_stat, df)
    return mean_diff, p_val, p_val < 0.05

# Run Games-Howell for each pair
results = []
for cat1, cat2 in category_pairs:
    mean_diff, p_val, sig = games_howell(groups[cat1], groups[cat2])
    results.append({
        'Group1': cat1,
        'Group2': cat2,
        'Mean Diff': mean_diff,
        'p-value': p_val,
        'Significant': sig
    })

# Convert to DataFrame
gh_df = pd.DataFrame(results)
print(gh_df.head())

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Barplot of average ratings by category
plt.figure(figsize=(12,6))
sns.barplot(data=df, x='category', y='Rate', errorbar='sd', palette='Blues',hue='category')
plt.xticks(rotation=45, ha='right')
plt.title('Average Customer Ratings by Category')
plt.ylabel('Average Rating')
plt.xlabel('Category')
plt.tight_layout()
plt.show()


# 2. Heatmap of Games-Howell p-values
# Create a square matrix of categories with p-values from gh_df

categories = df['category'].unique()
categories.sort()
p_matrix = pd.DataFrame(np.ones((len(categories), len(categories))), index=categories, columns=categories)

for _, row in gh_df.iterrows():
    g1, g2 = row['Group1'], row['Group2']
    p_val = row['p-value']
    p_matrix.loc[g1, g2] = p_val
    p_matrix.loc[g2, g1] = p_val  # symmetric

plt.figure(figsize=(12,10))
sns.heatmap(p_matrix, annot=True, fmt=".3f", cmap='coolwarm_r', cbar_kws={'label': 'p-value'}, vmax=0.05)
plt.title('Games-Howell Post Hoc Test p-value Heatmap')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()